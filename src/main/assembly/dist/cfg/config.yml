#
# dd-dataverse-ingest configuration file
#

#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#server
#
server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20360
  adminConnectors:
    - type: http
      port: 20361
  requestLog:
    appenders:
      - type: file
        archive: false
        timeZone: system
        currentLogFilename: /var/opt/dans.knaw.nl/log/dd-dataverse-ingest/request.log

#
# Configuration for the YAML service. Currently only supports configuring the loader options.
#
yamlServiceConfig:
  loaderOptions:
    codePointLimit: 6291456 # 6 MiB

#
# Parameters related to communication with the Dataverse instance
#
dataverse:
  baseUrl: 'http://localhost:8080'
  apiKey: 'changeme'
  awaitLockStateMaxNumberOfRetries: 30
  awaitLockStateMillisecondsBetweenRetries: 500
  # Await indexing for a maximum of 1 hour (720 * 5 sec = 3600 sec = 1 h).
  awaitIndexingMaxNumberOfRetries: 720
  awaitIndexingMillisecondsBetweenRetries: 5000
  httpClient:
    timeout: 45min
    connectionTimeout: 15s
    connectionRequestTimeout: 15s
    timeToLive: 1h
    retries: 2
    userAgent: dd-dataverse-ingest
#
# Settings related to ingest services.
#
ingest:
  # Deposits dropped in the inbox will automatically be picked up and processed by the ingest service.
  autoIngest:
    # apiKey: 'changeme' # overrides the apiKey from the dataverse section
    inbox: /var/opt/dans.knaw.nl/tmp/auto-ingest/inbox
    outbox: /var/opt/dans.knaw.nl/tmp/auto-ingest/outbox
    # Forces the service to require the bag in the deposit to conform to the DANS BagIt Profile. Without this SWORD depositors would have the full range of options offered by
    # the Dataverse Ingest Deposit instruction files, so it is not recommended to disable this. The default is 'yes'.
    requireDansBag: yes
    # How often to check for new deposits in the inbox. The service will check for new deposits every 5 seconds by default.
    # pollingInterval: 5s
  # Import of migration deposits. This area is used to migrate datasets from EASY to Dataverse and differs from import only in the way the DANS deposits are converted
  # to Dataverse Ingest deposits.
  migration:
    # apiKey: 'changeme' # overrides the apiKey from the dataverse section
    inbox: /var/opt/dans.knaw.nl/tmp/migration/deposits
    outbox: /var/opt/dans.knaw.nl/tmp/migration/out
    # Forces the service to require the bag in the deposit to conform to the DANS BagIt Profile. Without this SWORD depositors would have the full range of options offered by
    # the Dataverse Ingest Deposit instruction files, so it is not recommended to disable this. The default is 'yes'.
    requireDansBag: yes
  # Import of deposits. This area is used for manual bulk imports of deposits.
  import:
    # apiKey: 'changeme' # overrides the apiKey from the dataverse section
    inbox: /var/opt/dans.knaw.nl/tmp/import/inbox
    outbox: /var/opt/dans.knaw.nl/tmp/import/outbox
    # Allow Dataverse Ingest Deposits for import. Import should only be accessible to application manager.
    requireDansBag: no
  tempDir: /var/opt/dans.knaw.nl/tmp/zip-wrapping
  #
  # If some of the metadata blocks are secured with a secret key, the key must be included in the metadataKeys map below, as follows:
  #
  # metadataKeys:
  #    <metadata-block-name>: '<secret-key-value>'
  #
  metadataKeys: { }
  #
  # The maximum number of files that the service will upload in a single batch. If :ZipUploadFilesLimit is set to a lower number than this,
  # the lower number will be used, so that Dataverse will not include the batch as one zip file in the dataset instead of unpacking it.
  #
  # See: https://guides.dataverse.org/en/latest/installation/config.html#zipuploadfileslimit
  #
  maxNumberOfFilesPerUploadBatch: 1000
  maxByteSizePerUploadBatch: 500MiB

  #
  # The service waits for the dataset to reach the released state before it continues processing the next deposit. These settings control how long the service waits,
  # before giving up and marking the deposit as failed.
  #
  waitForReleasedState:
    # Start polling for the dataset state after this time x number of files in the dataset. It is expected that releasing a dataset takes at least this amount of time.
    leadTimePerFile: 20ms
    # Give up waiting for the dataset to be in the expected state after this time. The lead time is *not* included in this timeout.
    timeout: 1h
    # The interval between polling the dataset state.
    pollingInterval: 5s

#
# Settings related to the conversion of deposits from the legacy format to the format used by the ingest service. Set to null to disable.
#
dansDepositConversion:
  #
  # Filtering. Files with a path matching the pattern will not be added to the dataset. Renaming/moving files is not affected.
  # By default, no files are excluded.
  #
  fileExclusionPattern: 'a^'

  #
  # Files that must be uploaded separate from the rest of the files in the deposit. The pattern is a regular expression.
  #
  filesForSeparateUploadPattern: '^.*\.shp$'

  #
  # File paths to exclude from embargoes.
  #
  embargoExclusions:
    - original-metadata.zip
    - easy-migration.zip

  #
  # Map from depositor.userId to organization name. Used to fill in the dansDataSupplier metadata field. If there is no
  # entry for a depositor, dansDataSupplier will be left empty.
  #
  dataSuppliers: { }
  # user001: The Organization Name

  #
  # If true, try to deduplicate multi-value metadata fields. If false, do not deduplicate.
  #
  deduplicate: true

  #
  # The directory where various metadata term mappings are stored.
  #
  mappingDefsDir: /etc/opt/dans.knaw.nl/dd-dataverse-ingest

  #
  # Role to assign to the depositor of the dataset, per use-case.
  #
  assignDepositorRole:
    autoIngest: swordupdater
    migration: contributorplus # Also used for import. In practice, the import use-case is not used for conversion


  #
  # Roles the depositor must have to be able to edit and publish the dataset, per use-case.
  #
  depositorAuthorization:
    autoIngest:
      editDataset: swordupdater
      publishDataset: swordpublisher
    migration: # Also used for import. In practice, the import use-case is not used for conversion
      editDataset: contributorplus
      publishDataset: dsContributor

  #
  # List of fields to skip, even when they are in active metadata blocks. This can be used if hidden fields in active metadata blocks are the target of a mapping. Normally, the mapping
  # would be applied to the hidden field. This leads to values that are displayed but cannot be edited (the normal Dataverse behavior for hidden fields). In cases where this is not desired,
  # the field can be skipped by adding it to the list below.
  #
  skipFields: [ ]


  validateDansBag:
    url: 'http://localhost:20330/'
    healthCheck:
      name: dd-validate-dans-bag
      pingUrl: 'http://localhost:20331/ping'
    httpClient:
      timeout: 45min
      connectionTimeout: 15s
      connectionRequestTimeout: 15s
      timeToLive: 1h
      retries: 2
      userAgent: dd-dataverse-ingest


#
# Health check scheduling
#
health:
  delayedShutdownHandlerEnabled: false
  initialOverallState: false
  healthChecks:
    - name: dataverse
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s
    - name: dd-validate-dans-bag
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s

#
# Deposits will only proceed if these dependencies are ready. The check is done at the start of each deposit task.
#
dependenciesReadyCheck:
  healthChecks:
    - dataverse
    - dd-validate-dans-bag
  pollInterval: 5s


#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#logging
#
logging:
  level: INFO
  appenders:
    - type: file
      archive: false
      timeZone: system
      logFormat: "%-5p [%d{ISO8601}] %c{0}: %m%n%dwREx"
      currentLogFilename: /var/opt/dans.knaw.nl/log/dd-dataverse-ingest/dd-dataverse-ingest.log
    - type: console
      # Used in combination with journald, which already adds the timestamp
      logFormat: "%-5p %c{0}: %m%n%dwREx"
  loggers:
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'
